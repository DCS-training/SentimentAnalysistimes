{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of *The Times* Music Reviews\n",
    "## Part V: Comparison of Manual and VADER Sentiment Scores\n",
    "*How have artforms been reported?  Is there a status hierarchy between them?  How has this changed over time?*\n",
    "\n",
    "* **Project:** What counts as culture?  Reporting and criticism in The Times 1785-2000\n",
    "* **Project Lead:** Dave O'Brien (lead), Lucy Havens (Jupyter Notebook author), Orian Brooke, Mark Taylor\n",
    "* **Funding:** from the Centre for Data, Culture & Society, University of Edinburgh\n",
    "* **Dataset:** 83,625 reviews about music published in The Times from 1950 through 2009 from The Times Archive\n",
    "\n",
    "Begun February 2021\n",
    "\n",
    "***\n",
    "#### Table of Contents\n",
    "1. [Prepare the Data](#prepare)\n",
    "\n",
    "    1.1 [Select Reviews for Manual Sentiment Analysis](#select)\n",
    "    \n",
    "    1.2 [Load Sentiment Scores](#load)\n",
    "    \n",
    "2. [Analyze the Data](#analyze)\n",
    "\n",
    "    2.1 [Manual Scores and VADER Scores](#analyze)\n",
    "***\n",
    "\n",
    "<a name=\"prepare\"></a>\n",
    "## 1. Prepare the Data\n",
    "\n",
    "Before we can begin coding, we must first import the programming libraries we'd like to use in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data loading\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For text analysis\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.text import Text\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('tagsets')  # part of speech tags\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt   ###  Need to figure out why Altair returns error! (Javascript Error: Unrecognized transform type: \"formula\")\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"select\"></a>\n",
    "### 1.1 Select Reviews for Manual Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of how well the sentiment analyzer performs, we can read some of these reviews and judge for ourselves whether the VADER scores seem accurate!  \n",
    "\n",
    "Let's randomly select music reviews with at least one of the four genres we're focusing on (opera, jazz, rap, and rock), getting a selection of articles published in every year from 1950 through 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a DataFrame of reviews and their sentiment scores\n",
    "df = pd.read_csv(\"../TheTimes_DaveO/TheTimesArticles_1950-2009_MetadataWithVADERSentiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opera articles: 18628\n",
      "Jazz articles: 7681\n",
      "Rap articles: 1925\n",
      "Rock articles: 9222\n"
     ]
    }
   ],
   "source": [
    "#  Input: music-related term and a DataFrame of music review metadata\n",
    "# Output: a list of booleans (True or False) noting which reviews have the input term\n",
    "def termFilter(term_string, dataframe):\n",
    "    df_terms = list(dataframe.term)\n",
    "    with_term = []\n",
    "    for t in df_terms:\n",
    "        if term_string in t:\n",
    "            with_term += [True]\n",
    "        else:\n",
    "            with_term += [False]\n",
    "    \n",
    "    assert(len(with_term) == len(df_terms))\n",
    "    return with_term\n",
    "\n",
    "# Determine which music reviews have the words opera, jazz, rap, and rock\n",
    "with_opera = termFilter(\"opera\", df)\n",
    "with_jazz = termFilter(\"jazz\", df)\n",
    "with_rap = termFilter(\"rap\", df)\n",
    "with_rock = termFilter(\"rock\", df)\n",
    "\n",
    "# Add the lists of booleans to the DataFrame of music review metadata (including sentiment scores)\n",
    "df[\"with_opera\"] = with_opera\n",
    "df[\"with_jazz\"] = with_jazz\n",
    "df[\"with_rap\"] = with_rap\n",
    "df[\"with_rock\"] = with_rock\n",
    "\n",
    "# Create subsets of data, making one DataFrame of music reviews per genre\n",
    "df_opera = df[df.with_opera == True]\n",
    "df_jazz = df[df.with_jazz == True]\n",
    "df_rap = df[df.with_rap == True]\n",
    "df_rock = df[df.with_rock == True]\n",
    "print(\"Opera articles:\",df_opera.shape[0])\n",
    "print(\"Jazz articles:\",df_jazz.shape[0])\n",
    "print(\"Rap articles:\",df_rap.shape[0])\n",
    "print(\"Rock articles:\",df_rock.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D list of files for each genre, with one list per year of publication\n",
    "def listsOfArticlesPerYear(dataframe):\n",
    "    # Get a non-repeating list of all years in the dataframe\n",
    "    years = dataframe.year.unique()\n",
    "    articles = []\n",
    "    for y in years:\n",
    "        # For each year, create a list of articles published in that year\n",
    "        # and add those articles' identifiers to a list \n",
    "        articles += [list(dataframe[dataframe.year == y].filepath)]\n",
    "    # Return the two-dimensional list of articles (one sub-list per year) \n",
    "    return articles\n",
    "\n",
    "opera_ids = listsOfArticlesPerYear(df_opera)\n",
    "# print(opera_ids[1:2])\n",
    "jazz_ids = listsOfArticlesPerYear(df_jazz)\n",
    "rap_ids = listsOfArticlesPerYear(df_rap)\n",
    "rock_ids = listsOfArticlesPerYear(df_rock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of publication years for our corpus: 60\n",
      "\n",
      "Opera articles to read: 60\n",
      "Jazz articles to read: 60\n",
      "Rap articles to read: 42\n",
      "Rock articles to read: 60\n",
      "\n",
      "Articles to read: 222\n"
     ]
    }
   ],
   "source": [
    "year_entries = len(df.year.unique())\n",
    "print(\"Number of publication years for our corpus:\",year_entries)\n",
    "\n",
    "# Randomly select one article from each year from each genre's identifiers lists\n",
    "def randomSelection(twoDlist):\n",
    "    to_read = []\n",
    "    for year_of_articles in twoDlist:\n",
    "        to_read += [random.choice(year_of_articles)]\n",
    "    return to_read\n",
    "\n",
    "read_opera = randomSelection(opera_ids)\n",
    "print(\"\\nOpera articles to read:\", len(read_opera))\n",
    "read_jazz = randomSelection(jazz_ids)\n",
    "print(\"Jazz articles to read:\", len(read_jazz))\n",
    "read_rap = randomSelection(rap_ids)\n",
    "print(\"Rap articles to read:\", len(read_rap))\n",
    "read_rock = randomSelection(rock_ids)\n",
    "print(\"Rock articles to read:\", len(read_rock))\n",
    "print(\"\\nArticles to read:\",len(read_opera)+len(read_jazz)+len(read_rap)+len(read_rock))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also going to add five articles with the maximum and minimum VADER scores to our subset of articles to read and manually analyze the sentiment of tem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TheTimesMusicReviews_1950-2009_part1/70658', 'TheTimesMusicReviews_1950-2009_part1/64287']\n",
      "Total articles to read: 227\n"
     ]
    }
   ],
   "source": [
    "max_min_scores = [70658, 64287, 21217, 98832, 72571]\n",
    "to_read = []\n",
    "for identifier in max_min_scores:\n",
    "    filepath = list(df.filepath[df.identifier == identifier])[0]\n",
    "    identifier = re.findall(\"\\d{5,}\", filepath)[0]\n",
    "    to_read.append(filepath)\n",
    "\n",
    "def flattenTwoDLists(genre_list, to_read):\n",
    "    for id_list in genre_list:\n",
    "        for filepath in id_list:\n",
    "            to_read += [filepath]\n",
    "    return to_read\n",
    "\n",
    "to_read_ids = flattenTwoDLists([read_opera, read_jazz, read_rock, read_rap], to_read)\n",
    "print(to_read_ids[0:2])\n",
    "print(\"Total articles to read:\", len(to_read_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's export the selected reviews so we can read and manually score their sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheTimesMusicReviews_1950-2009_part1/20787\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../TheTimes_DaveO/TheTimesMusicReviews_1950-2009\"\n",
    "articles = PlaintextCorpusReader(data_path, \".+/.+\", encoding='utf-8')\n",
    "fileids = articles.fileids()\n",
    "print(fileids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files ready for manual sentiment analysis in the directory ToReadAndScore!\n"
     ]
    }
   ],
   "source": [
    "for filepath in to_read_ids:\n",
    "    file = open(\"../TheTimes_DaveO/ToReadAndScore/\"+str(filepath), \"a\")\n",
    "    file.write(articles.raw(filepath))\n",
    "    file.close()\n",
    "    \n",
    "print(\"Files ready for manual sentiment analysis in the directory ToReadAndScore!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the division of the files is relatively equal in word length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dave_path =  \"../TheTimes_DaveO/ToReadAndScore/Dave\"\n",
    "dave = PlaintextCorpusReader(dave_path, \".+\", encoding='utf-8')\n",
    "dave_tokens = dave.words()\n",
    "orian_path =  \"../TheTimes_DaveO/ToReadAndScore/Orian\"\n",
    "orian = PlaintextCorpusReader(orian_path, \".+\", encoding='utf-8')\n",
    "orian_tokens = orian.words()\n",
    "lucy_path =  \"../TheTimes_DaveO/ToReadAndScore/Lucy\"\n",
    "lucy = PlaintextCorpusReader(lucy_path, \".+\", encoding='utf-8')\n",
    "lucy_tokens = lucy.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76739\n",
      "76396\n",
      "62749\n"
     ]
    }
   ],
   "source": [
    "print(len(dave_tokens))\n",
    "print(len(orian_tokens))\n",
    "print(len(lucy_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  After scoring these articles, we'll compare our manually calculated sentiment scores with the scores VADER assigns in the sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"load\"></a>\n",
    "### 1.2 Load Sentiment Scores\n",
    "**Step 1:** Load the data with VADER scores for each review in our corpus of articles from The Times as a DataFrame (which is a type of table used in the Python library pandas) called `vader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reviews (rows in table): 83625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>author</th>\n",
       "      <th>term</th>\n",
       "      <th>section</th>\n",
       "      <th>pages</th>\n",
       "      <th>filename</th>\n",
       "      <th>article_id</th>\n",
       "      <th>issue_id</th>\n",
       "      <th>filepath</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20787</td>\n",
       "      <td>SOME NEW SCORES MOTET AND OPERA</td>\n",
       "      <td>1950</td>\n",
       "      <td>BY OUR MUSIC CRITIC</td>\n",
       "      <td>[' bands', ' composer', ' musical', ' opera', ...</td>\n",
       "      <td>Reviews</td>\n",
       "      <td>[]</td>\n",
       "      <td>/lustre/home/dc125/shared/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-1950-JUN30-008-023</td>\n",
       "      <td>0FFO-1950-JUN30</td>\n",
       "      <td>TheTimesMusicReviews_1950-2009_part1/20787</td>\n",
       "      <td>0.9897</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20788</td>\n",
       "      <td>THE ROYAL OPERA \" TRISTAN AND ISOLDE \"</td>\n",
       "      <td>1950</td>\n",
       "      <td>''</td>\n",
       "      <td>[' opera', ' orchestra']</td>\n",
       "      <td>Reviews</td>\n",
       "      <td>[]</td>\n",
       "      <td>/lustre/home/dc125/shared/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-1950-JUN30-008-027</td>\n",
       "      <td>0FFO-1950-JUN30</td>\n",
       "      <td>TheTimesMusicReviews_1950-2009_part1/20788</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20789</td>\n",
       "      <td>GROWING TASTE FOR MUSIC PLEA FOR ENLARGED QUEE...</td>\n",
       "      <td>1950</td>\n",
       "      <td>''</td>\n",
       "      <td>[' country']</td>\n",
       "      <td>Reviews</td>\n",
       "      <td>[]</td>\n",
       "      <td>/lustre/home/dc125/shared/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-1950-JUN30-008-032</td>\n",
       "      <td>0FFO-1950-JUN30</td>\n",
       "      <td>TheTimesMusicReviews_1950-2009_part1/20789</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identifier                                              title  year  \\\n",
       "0       20787                    SOME NEW SCORES MOTET AND OPERA  1950   \n",
       "1       20788             THE ROYAL OPERA \" TRISTAN AND ISOLDE \"  1950   \n",
       "2       20789  GROWING TASTE FOR MUSIC PLEA FOR ENLARGED QUEE...  1950   \n",
       "\n",
       "                author                                               term  \\\n",
       "0  BY OUR MUSIC CRITIC  [' bands', ' composer', ' musical', ' opera', ...   \n",
       "1                   ''                           [' opera', ' orchestra']   \n",
       "2                   ''                                       [' country']   \n",
       "\n",
       "   section pages                                           filename  \\\n",
       "0  Reviews    []  /lustre/home/dc125/shared/TDA_GDA_1785-2009/19...   \n",
       "1  Reviews    []  /lustre/home/dc125/shared/TDA_GDA_1785-2009/19...   \n",
       "2  Reviews    []  /lustre/home/dc125/shared/TDA_GDA_1785-2009/19...   \n",
       "\n",
       "                article_id         issue_id  \\\n",
       "0  0FFO-1950-JUN30-008-023  0FFO-1950-JUN30   \n",
       "1  0FFO-1950-JUN30-008-027  0FFO-1950-JUN30   \n",
       "2  0FFO-1950-JUN30-008-032  0FFO-1950-JUN30   \n",
       "\n",
       "                                     filepath  compound  positive  neutral  \\\n",
       "0  TheTimesMusicReviews_1950-2009_part1/20787    0.9897     0.075    0.912   \n",
       "1  TheTimesMusicReviews_1950-2009_part1/20788    0.9978     0.230    0.744   \n",
       "2  TheTimesMusicReviews_1950-2009_part1/20789    0.9912     0.124    0.866   \n",
       "\n",
       "   negative  \n",
       "0     0.013  \n",
       "1     0.025  \n",
       "2     0.010  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader = pd.read_csv(\"../TheTimes_DaveO/TheTimesArticles_1950-2009_MetadataWithVADERSentiments.csv\")\n",
    "vader.drop(columns={\"Unnamed: 0\"}, inplace=True)\n",
    "print(\"Total Reviews (rows in table):\", vader.shape[0])\n",
    "vader.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** *For this data, the compound score is VADER's overall score for an article, with -1 being most negative, -0.5 to 0.5 being neutral, and 1 being most positive.  The positive, neutral, and negative scores represent the proportion of text VADER interprets as haivng a positive, neutral, or negative sentiment, so these scores are between 0 and 1.  [Visit the VADER GitHub repository for more information on VADER scoring](https://github.com/cjhutto/vaderSentiment#about-the-scoring).*\n",
    "\n",
    "**Step 2:** Load the data of manual sentiment scores as DataFrames `man1`, `man2`, and `man3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>manual score</th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71435</td>\n",
       "      <td>5</td>\n",
       "      <td>dave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71703</td>\n",
       "      <td>5</td>\n",
       "      <td>dave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72059</td>\n",
       "      <td>5</td>\n",
       "      <td>dave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identifier manual score person\n",
       "0       70928          NaN   dave\n",
       "1       71118          NaN   dave\n",
       "2       71435            5   dave\n",
       "3       71703            5   dave\n",
       "4       72059            5   dave"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man1 = pd.read_csv(\"ManualSentimentScores/manual-scores-dave.csv\", header=None, names=[\"identifier\", \"manual score\"])\n",
    "man1[\"person\"] = \"dave\"\n",
    "man2 = pd.read_csv(\"ManualSentimentScores/manual-scores-lucy.csv\", header=None, names=[\"identifier\", \"manual score\"])\n",
    "man2[\"person\"] = \"lucy\"\n",
    "man3 = pd.read_csv(\"ManualSentimentScores/manual-scores-orian.csv\", header=None, names=[\"identifier\", \"manual score\"])\n",
    "man3[\"person\"] = \"orian\"\n",
    "man1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** *For this data, each included article was only given one manual score by one person on a scale of 1 to 5, 1 being very negative, 3 being neutral, and 5 being very positive.*\n",
    "\n",
    "**Step 3:** Merge the DataFrames of manual scores and VADER scores.\n",
    "\n",
    "We want to compare the VADER sentiment scores to the manually-assigned sentiment scores, so we'll use the *identifier* column of our DataFrames to filter out articles from `vader` that are not included.  We'll drop any scores that aren't an integer, as these indicate reviews that are not about one of our genres of interest (opera, rock, rap, and jazz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217, 3)\n",
      "(110, 3)\n"
     ]
    }
   ],
   "source": [
    "# Combine the manual sentiment score DataFrames into one dataframe\n",
    "man = (man1.append(man2)).append(man3)\n",
    "print(man.shape)\n",
    "man.dropna(inplace=True)\n",
    "to_drop = []\n",
    "for index,row in man.iterrows():\n",
    "    # Find all rows with value NA, N/A, na, or n/a\n",
    "    if len(re.findall(\"\\D\", row[\"manual score\"])) > 0:\n",
    "        to_drop += [index]\n",
    "man.drop(to_drop, inplace=True)\n",
    "print(man.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 out of 217 articles, or about 51%, were reviews about our music genres of interest\n"
     ]
    }
   ],
   "source": [
    "print(\"110 out of 217 articles, or about \"+str(round((110/217)*100))+\"%, \"+\"were reviews about our music genres of interest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not a great result our corpus, if just over half of the articles are actually about the music genres of opera, rock, rap, or jazz!  \n",
    "\n",
    "***Future Work:*** *When manually scoring the articles, we noted several words that may be of use for further filtering the corpus to reduce the number of false positives it contains.  For now, we'll work with the corpus as is, and in the future we can see how much that further filtering improves the quality of the corpus.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5' '1' '3' '4' '2']\n",
      "[5 1 3 4 2]\n"
     ]
    }
   ],
   "source": [
    "print(man[\"manual score\"].unique()) # Check that only strings of numbers 1 through 5 are values\n",
    "man[\"manual score\"] = pd.to_numeric(man[\"manual score\"])\n",
    "print(man[\"manual score\"].unique()) # Check that only integers 1 through 5 are values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the VADER scores for each article in the 'man' DataFrame\n",
    "man_ids = list(man.identifier)\n",
    "compound = []\n",
    "positive = []\n",
    "neutral = []\n",
    "negative = []\n",
    "for i in man_ids:\n",
    "    compound += [list(vader[vader[\"identifier\"] == i][\"compound\"])[0]]\n",
    "    positive += [list(vader[vader[\"identifier\"] == i][\"positive\"])[0]]\n",
    "    neutral += [list(vader[vader[\"identifier\"] == i][\"neutral\"])[0]]\n",
    "    negative += [list(vader[vader[\"identifier\"] == i][\"negative\"])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>manual score</th>\n",
       "      <th>person</th>\n",
       "      <th>VADER compound</th>\n",
       "      <th>VADER positive</th>\n",
       "      <th>VADER neutral</th>\n",
       "      <th>VADER negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71703</td>\n",
       "      <td>5</td>\n",
       "      <td>dave</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72059</td>\n",
       "      <td>5</td>\n",
       "      <td>dave</td>\n",
       "      <td>0.9929</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72950</td>\n",
       "      <td>1</td>\n",
       "      <td>dave</td>\n",
       "      <td>-0.7537</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73995</td>\n",
       "      <td>5</td>\n",
       "      <td>dave</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>74373</td>\n",
       "      <td>5</td>\n",
       "      <td>dave</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    identifier  manual score person  VADER compound  VADER positive  \\\n",
       "3        71703             5   dave          0.9879           0.141   \n",
       "4        72059             5   dave          0.9929           0.151   \n",
       "7        72950             1   dave         -0.7537           0.081   \n",
       "8        73995             5   dave          0.9995           0.108   \n",
       "10       74373             5   dave          0.9804           0.105   \n",
       "\n",
       "    VADER neutral  VADER negative  \n",
       "3           0.832           0.026  \n",
       "4           0.829           0.020  \n",
       "7           0.823           0.096  \n",
       "8           0.852           0.040  \n",
       "10          0.867           0.029  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the VADER scores to 'man'\n",
    "man[\"VADER compound\"] = compound\n",
    "man[\"VADER positive\"] = positive\n",
    "man[\"VADER neutral\"] = neutral\n",
    "man[\"VADER negative\"] = negative\n",
    "man.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- OPTION 1:\n",
    "Since the manual scores and VADER scores use different scales ([see VADER's here](https://github.com/cjhutto/vaderSentiment#about-the-scoring)), we'll normalize and generalize the scores according to the following:\n",
    "* manual 5 = VADER compound 0.7501-1\n",
    "* manual 4 = VADER compound 0.5001-0.75\n",
    "* manual 3 = VADER compound -0.5-0.5\n",
    "* manual 2 = VADER compound  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the `man` DataFrame to a CSV file for quick reference in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "man.to_csv(\"sentiment-scores-vader-manual.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"analyze\"></a>\n",
    "## 2. Analyze the Data\n",
    "### 2.1 Manual Scores and VADER Scores\n",
    "Let's compare the manually-assigned scores to VADER's compound scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For reviews given manual score 1:\n",
      " - Lowest VADER Compound Score: -0.7537\n",
      " - Highest VADER Compound Score: 0.991\n",
      " - Standard Deviation: 0.7181025382981209\n",
      "For reviews given manual score 2:\n",
      " - Lowest VADER Compound Score: -0.9806\n",
      " - Highest VADER Compound Score: 0.9983\n",
      " - Standard Deviation: 0.7961459447688601\n",
      "For reviews given manual score 3:\n",
      " - Lowest VADER Compound Score: -0.34600000000000003\n",
      " - Highest VADER Compound Score: 0.9975\n",
      " - Standard Deviation: 0.38149727912429304\n",
      "For reviews given manual score 4:\n",
      " - Lowest VADER Compound Score: -0.9876\n",
      " - Highest VADER Compound Score: 0.9996\n",
      " - Standard Deviation: 0.41468518178703956\n",
      "For reviews given manual score 5:\n",
      " - Lowest VADER Compound Score: 0.6956\n",
      " - Highest VADER Compound Score: 0.9999\n",
      " - Standard Deviation: 0.07685059086286991\n"
     ]
    }
   ],
   "source": [
    "scores = list(man[\"manual score\"].unique())\n",
    "scores.sort()\n",
    "def printScores(type):\n",
    "    for score in scores:\n",
    "        man_score = man[man[\"manual score\"] == score]\n",
    "        print(\"For reviews given manual score \"+str(score)+\":\")\n",
    "        print(\" - Lowest VADER \"+type.capitalize()+\" Score:\",min(man_score[\"VADER \"+type]))\n",
    "        print(\" - Highest VADER \"+type.capitalize()+\" Score:\",max(man_score[\"VADER \"+type]))\n",
    "        print(\" - Standard Deviation:\", np.std(man_score[\"VADER \"+type]))\n",
    "    return\n",
    "printScores(\"compound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER's scores seem to correspond pretty well for very positive reviews with a manual score 5, but there's much greater variation for the less positive reviews with a manual score of 4 or less.\n",
    "\n",
    "Let's see how VADER's positive, negative, and neutral scores relate to the manual scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For reviews given manual score 1:\n",
      " - Lowest VADER Positive Score: 0.081\n",
      " - Highest VADER Positive Score: 0.13699999999999998\n",
      " - Standard Deviation: 0.018251083277885903\n",
      "For reviews given manual score 2:\n",
      " - Lowest VADER Positive Score: 0.046\n",
      " - Highest VADER Positive Score: 0.173\n",
      " - Standard Deviation: 0.03358829489150957\n",
      "For reviews given manual score 3:\n",
      " - Lowest VADER Positive Score: 0.0\n",
      " - Highest VADER Positive Score: 0.16899999999999998\n",
      " - Standard Deviation: 0.039134671218108895\n",
      "For reviews given manual score 4:\n",
      " - Lowest VADER Positive Score: 0.076\n",
      " - Highest VADER Positive Score: 0.187\n",
      " - Standard Deviation: 0.027552393271728683\n",
      "For reviews given manual score 5:\n",
      " - Lowest VADER Positive Score: 0.067\n",
      " - Highest VADER Positive Score: 0.209\n",
      " - Standard Deviation: 0.03065794712994042\n"
     ]
    }
   ],
   "source": [
    "printScores(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For reviews given manual score 1:\n",
      " - Lowest VADER Negative Score: 0.036000000000000004\n",
      " - Highest VADER Negative Score: 0.102\n",
      " - Standard Deviation: 0.022043556141125204\n",
      "For reviews given manual score 2:\n",
      " - Lowest VADER Negative Score: 0.018000000000000002\n",
      " - Highest VADER Negative Score: 0.124\n",
      " - Standard Deviation: 0.02902036902215095\n",
      "For reviews given manual score 3:\n",
      " - Lowest VADER Negative Score: 0.0\n",
      " - Highest VADER Negative Score: 0.075\n",
      " - Standard Deviation: 0.019795319428599197\n",
      "For reviews given manual score 4:\n",
      " - Lowest VADER Negative Score: 0.0\n",
      " - Highest VADER Negative Score: 0.319\n",
      " - Standard Deviation: 0.04972363623067002\n",
      "For reviews given manual score 5:\n",
      " - Lowest VADER Negative Score: 0.017\n",
      " - Highest VADER Negative Score: 0.129\n",
      " - Standard Deviation: 0.025434010475913718\n"
     ]
    }
   ],
   "source": [
    "printScores(\"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER seems to interpret the majority of The Times' reviews as having text with a neutral sentiment. \n",
    "\n",
    "***Future Work:*** *Perhaps by adding to VADER's lexicon with our own scores for words, we could help VADER better understand how our corpus expresses negative sentiment and improve VADER's performance for this project...we could also try other sentiment analyzers and see if their scores come closer to the manual scores!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For reviews given manual score 1:\n",
      " - Lowest VADER Neutral Score: 0.773\n",
      " - Highest VADER Neutral Score: 0.8540000000000001\n",
      " - Standard Deviation: 0.02794089972694189\n",
      "For reviews given manual score 2:\n",
      " - Lowest VADER Neutral Score: 0.773\n",
      " - Highest VADER Neutral Score: 0.867\n",
      " - Standard Deviation: 0.02780336057932804\n",
      "For reviews given manual score 3:\n",
      " - Lowest VADER Neutral Score: 0.795\n",
      " - Highest VADER Neutral Score: 1.0\n",
      " - Standard Deviation: 0.04981856354167994\n",
      "For reviews given manual score 4:\n",
      " - Lowest VADER Neutral Score: 0.5870000000000001\n",
      " - Highest VADER Neutral Score: 0.908\n",
      " - Standard Deviation: 0.05396776236791738\n",
      "For reviews given manual score 5:\n",
      " - Lowest VADER Neutral Score: 0.662\n",
      " - Highest VADER Neutral Score: 0.8859999999999999\n",
      " - Standard Deviation: 0.043726719996664117\n"
     ]
    }
   ],
   "source": [
    "printScores(\"neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at these scores, I'd guess that VADER does a better job identifying positive sentiment in our corpus than neutral and negative sentiment, and that it's mistaking many negative sentiments for neutral sentiments.  What do you think?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
