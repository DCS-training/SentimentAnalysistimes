{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of The Times Music Reviews\n",
    "## Part I: Data Preparation\n",
    "*How have artforms been reported?  Is there a status hierarchy between them?  How has this changed over time?*\n",
    "\n",
    "* **Project:** What counts as culture?  Reporting and criticism in The Times 1785-2000\n",
    "* **Project Lead:** Dave O'Brien\n",
    "* **Developer:** Lucy Havens\n",
    "* **Funding:** from the Centre for Data, Culture & Society, University of Edinburgh\n",
    "\n",
    "Begun February 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data\n",
    "Import programming libraries needed for data loading and tranformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data loading\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/defoe-code/defoe/blob/master/queries/music_genres.txt\n",
    "genres = [\"Music\", \"African\", \"Big Band\", \"Bluegrass\", \"Country\", \"Blues\", \"Musical\", \"Classical\", \"Electronic\",\n",
    "          \"Folk\", \"Gospel\", \"Hip Hop\", \"Jazz\", \"Latin\", \"Metal\", \"Easy Listening\", \"Opera\", \"Pop\", \"Rap\", \"Rave\",\n",
    "          \"Reggae\", \"Rock\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819:\n",
      "- 'article_id:': 0FFO-1819-DEC01-001-004\n",
      "  'authors:': ''\n",
      "  filename: /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/1785_1909/0FFO-1819-DEC01.xml\n",
      "  issue_id: 0FFO-1819-DEC01\n",
      "  original text: \"PARLIAMIENTARY INTELLIGEATCE. HOUSE OF LORDS. TITTRAnAr NrlV. ?d)\\\n",
      "    \\ CASH PAVNMT,N''T.S. * TIiie H~ari of LAAUD~ERDALE, seeing a noble lord in his\\\n",
      "    \\ place, f4rom whom~ he -niighit expect to obtain information on a subject of\\\n",
      "    \\ imvportaiice respecting the currency of the country, wished to knowv whietheor\\\n",
      "    \\ there waLs any truith in a report whichl prevailed, that minis- ters intended\\\n",
      "    \\ to make a proposition to Pa-rliam-ent for preventing the resuimption of cashi-payments\\\n",
      "    \\ at the time fixed by the act 1' Thle Earl of LIVERPOOL did ,lot know uipon whlat\\\n",
      "    \\ grouind suchl an idea couild hiave been entertained by aniy part of tile public.\\\n",
      "    \\ ex- cep tht,in hi gratmetoplis te most absurdI and unfoundedc reprtsmigt otai\\\n",
      "    \\ crditfro soe; buthe-could assutre the\n"
     ]
    }
   ],
   "source": [
    "file = open(\"../TheTimes_DaveO/TimesMusicReviewsData/results_music_types_excluding_music_details\", \"r\")\n",
    "data = file.read()\n",
    "print(data[:1000])\n",
    "file.close()\n",
    "# YAML file format:\n",
    "#     Year\n",
    "#     - 'article_id:':\n",
    "#       'authors:' ''\n",
    "#       filename: ...\n",
    "#       issue_id: ...\n",
    "#       original text: \" .....\\\n",
    "#                        ......\"\n",
    "#       page_ids:\n",
    "#       - '000'\n",
    "#       - '000'\n",
    "#       - '000'\n",
    "#       term: ...\n",
    "#       title: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transform Data\n",
    "#### 2.1 Create a CSV file containing article metadata\n",
    "**Step 1:** Create a list of for each metadata field for all articles, meaning all article_ids are in one list, all authors are in another list, etc.  The lists should all be the same length, with one item for every article in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFileByLines(filepath):\n",
    "    file = open(filepath,'r')\n",
    "    lines_list = file.readlines()\n",
    "    file.close()\n",
    "    return lines_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataLists(lines_list):\n",
    "    article_ids, authors, filenames, issue_ids, terms, titles, years, original_texts, page_ids = [], [], [], [], [], [], [], [], []\n",
    "    y = ''\n",
    "    txt = False\n",
    "    pages = []\n",
    "    for line in lines_list:\n",
    "        # Check if the line is a year\n",
    "        date = re.findall(\"\\d{4}:\", line)\n",
    "        if len(date) != 0:\n",
    "            date = int(date[0][0:4])\n",
    "            # Valid dates should be no earlier than 1725\n",
    "            # and no later than 2000 in this corpus\n",
    "            if date >= 1725 and date <= 2000:\n",
    "                y = date\n",
    "        else:\n",
    "            if \"'article_id:':\" in line:\n",
    "                a_id = line.replace(\"'article_id:':\",\"\")\n",
    "                a_id = a_id.strip('-')\n",
    "                a_id = a_id.strip()\n",
    "            elif \"'authors:':\" in line:\n",
    "                auth = line.replace(\"'authors:':\", \"\")\n",
    "                auth = auth.strip()\n",
    "            elif \"filename:\" in line:\n",
    "                f = line.replace(\"filename:\",'')\n",
    "                f = f.strip()\n",
    "            elif 'issue_id:' in line:\n",
    "                i_id = line.replace('issue_id:','')\n",
    "                i_id = i_id.strip()\n",
    "            elif 'original text:' in line:\n",
    "                txt = line.replace('original text: \"','')\n",
    "                txt = txt.replace(\"\\\\\",\"\")\n",
    "                txt = txt.strip()\n",
    "            elif 'term:' in line:\n",
    "                term = line.replace('term:','')\n",
    "                term = term.strip()\n",
    "            elif re.search(\"- '(\\d)+'\", line) != None:\n",
    "                p = re.search(\"- '(\\d)+'\", line)[0]\n",
    "                p = p.strip('-')\n",
    "                p = p.strip()\n",
    "                p = p.strip(\"'\")\n",
    "                pages += [p]\n",
    "            # only the first line of the original text is preceded with a line name,\n",
    "            # so all lines without one of the line names above, without the line page_ids,\n",
    "            # and with backslashes are original text\n",
    "            elif ('page_ids:' not in line) and (\"  - \" not in line) and ('title:' not in line) and (txt):\n",
    "                txt_cont = line.replace(\"\\\\\",\"\")\n",
    "                txt_cont = txt_cont.strip()\n",
    "                txt += \" \" + txt_cont\n",
    "            elif 'title:' in line:\n",
    "                t = line.replace('title:','')\n",
    "                t = t.strip()\n",
    "                titles += [t]\n",
    "                # title is the last line per term details instance, so add the completed\n",
    "                # original text, pages and year the article was published after this line, along\n",
    "                # with all the remaining data, and reset the original text, year, and pages variables\n",
    "                txt = txt[:-1] # Remove ending quotation mark\n",
    "                original_texts += [txt]\n",
    "                txt = False\n",
    "                years += [y]\n",
    "                page_ids += [pages]\n",
    "                pages = []\n",
    "                article_ids += [a_id]\n",
    "                authors += [auth]\n",
    "                filenames += [f]\n",
    "                issue_ids += [i_id]\n",
    "                terms += [term]\n",
    "                \n",
    "    return article_ids, authors, filenames, issue_ids, terms, titles, years, original_texts, page_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_lines = readFileByLines(\"../TheTimes_DaveO/TimesMusicReviewsData/results_music_types_excluding_music_details\")\n",
    "article_ids, authors, filenames, issue_ids, terms, titles, years, original_texts, page_ids = createDataLists(times_lines)\n",
    "assert len(article_ids) == len(years)\n",
    "assert len(authors) == len(filenames)\n",
    "assert len(original_texts) == len(terms)\n",
    "assert len(issue_ids) == len(titles)\n",
    "assert len(page_ids) == len(original_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles: 2276\n"
     ]
    }
   ],
   "source": [
    "print(\"Total articles:\", len(article_ids))\n",
    "# print(len(authors))\n",
    "# print(len(filenames))\n",
    "# print(len(issue_ids))\n",
    "# print(len(terms))\n",
    "# print(len(titles))\n",
    "# print(len(years))\n",
    "# print(len(original_texts))\n",
    "# print(len(page_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARLIAMIENTARY INTELLIGEATCE. HOUSE OF LORDS. TITTRAnAr NrlV. ?d) CASH PAVNMT,N''T.S. * TIiie H~ari of LAAUD~ERDALE, seeing a noble lord in his place, f4rom whom~ he -niighit expect to obtain information on a subject of imvportaiice respecting the currency of the country, wished to knowv whietheor there waLs any truith in a report whichl prevailed, that minis- ters intended to make a proposition t\n",
      "TENTS.-Present . 110 Proxies-o x i6i8-178 Majority against the motion -131 Adjourned at OXE O'CLOCY.\n"
     ]
    }
   ],
   "source": [
    "print(original_texts[1][:400])\n",
    "print(original_texts[1][-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `\\` at the beginning of each line of `original text` and the `\"...\"` surrounding the entire `original text` entries have successfully been removed!\n",
    "\n",
    "**Step 2:** Create a DataFrame of all data except the article texts (`original_text: ...`), which organizes the data into a table for easy export as a CSV that can be viewed in Microsoft Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>author</th>\n",
       "      <th>term</th>\n",
       "      <th>pages</th>\n",
       "      <th>filename</th>\n",
       "      <th>article_id</th>\n",
       "      <th>issue_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PARLIAMIENTARY INTELLIGEATCE. HOUSE OF LORDS. ...</td>\n",
       "      <td>1819</td>\n",
       "      <td>''</td>\n",
       "      <td>country</td>\n",
       "      <td>[001, 002, 003]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...</td>\n",
       "      <td>0FFO-1819-DEC01-001-004</td>\n",
       "      <td>0FFO-1819-DEC01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARLIAMIENTARY INTELLIGEATCE. HOUSE OF LORDS. ...</td>\n",
       "      <td>1819</td>\n",
       "      <td>''</td>\n",
       "      <td>latin</td>\n",
       "      <td>[001, 002, 003]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...</td>\n",
       "      <td>0FFO-1819-DEC01-001-004</td>\n",
       "      <td>0FFO-1819-DEC01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOUSE OF COMMONS, Thursday, Dec. 2. A</td>\n",
       "      <td>1819</td>\n",
       "      <td>''</td>\n",
       "      <td>country</td>\n",
       "      <td>[001, 002, 003]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...</td>\n",
       "      <td>0FFO-1819-DEC03-001-002</td>\n",
       "      <td>0FFO-1819-DEC03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"TIOYJSS&gt; OP LORDA. Ptinw. Dr.a. \\xB67.\"</td>\n",
       "      <td>1819</td>\n",
       "      <td>''</td>\n",
       "      <td>country</td>\n",
       "      <td>[002, 003]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...</td>\n",
       "      <td>0FFO-1819-DEC18-002-001</td>\n",
       "      <td>0FFO-1819-DEC18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"TIOYJSS&gt; OP LORDA. Ptinw. Dr.a. \\xB67.\"</td>\n",
       "      <td>1819</td>\n",
       "      <td>''</td>\n",
       "      <td>rock</td>\n",
       "      <td>[002, 003]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...</td>\n",
       "      <td>0FFO-1819-DEC18-002-001</td>\n",
       "      <td>0FFO-1819-DEC18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HOUSE OF COMMONS, TtUEsDAY, Nov. B.</td>\n",
       "      <td>1819</td>\n",
       "      <td>''</td>\n",
       "      <td>country</td>\n",
       "      <td>[002, 003, 004]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...</td>\n",
       "      <td>0FFO-1819-NOV24-002-001</td>\n",
       "      <td>0FFO-1819-NOV24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HOUSE OF COMAMONS, WEDNESDAY. NOv. 24.</td>\n",
       "      <td>1819</td>\n",
       "      <td>''</td>\n",
       "      <td>country</td>\n",
       "      <td>[001, 002, 003]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...</td>\n",
       "      <td>0FFO-1819-NOV25-001-004</td>\n",
       "      <td>0FFO-1819-NOV25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HOUSE OF COMAMONS, WEDNESDAY. NOv. 24.</td>\n",
       "      <td>1819</td>\n",
       "      <td>''</td>\n",
       "      <td>gospel</td>\n",
       "      <td>[001, 002, 003]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...</td>\n",
       "      <td>0FFO-1819-NOV25-001-004</td>\n",
       "      <td>0FFO-1819-NOV25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOUSE OF COMAMONS, WEDNESDAY. NOv. 24.</td>\n",
       "      <td>1819</td>\n",
       "      <td>''</td>\n",
       "      <td>latin</td>\n",
       "      <td>[001, 002, 003]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...</td>\n",
       "      <td>0FFO-1819-NOV25-001-004</td>\n",
       "      <td>0FFO-1819-NOV25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PARLIAMENTARY INTELLIGENCE. H OUSE OF L,ORDS, ...</td>\n",
       "      <td>1820</td>\n",
       "      <td>''</td>\n",
       "      <td>country</td>\n",
       "      <td>[001, 002, 003]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...</td>\n",
       "      <td>0FFO-1820-OCT06-001-002</td>\n",
       "      <td>0FFO-1820-OCT06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  year author     term  \\\n",
       "0  PARLIAMIENTARY INTELLIGEATCE. HOUSE OF LORDS. ...  1819     ''  country   \n",
       "1  PARLIAMIENTARY INTELLIGEATCE. HOUSE OF LORDS. ...  1819     ''    latin   \n",
       "2              HOUSE OF COMMONS, Thursday, Dec. 2. A  1819     ''  country   \n",
       "3           \"TIOYJSS> OP LORDA. Ptinw. Dr.a. \\xB67.\"  1819     ''  country   \n",
       "4           \"TIOYJSS> OP LORDA. Ptinw. Dr.a. \\xB67.\"  1819     ''     rock   \n",
       "5                HOUSE OF COMMONS, TtUEsDAY, Nov. B.  1819     ''  country   \n",
       "6             HOUSE OF COMAMONS, WEDNESDAY. NOv. 24.  1819     ''  country   \n",
       "7             HOUSE OF COMAMONS, WEDNESDAY. NOv. 24.  1819     ''   gospel   \n",
       "8             HOUSE OF COMAMONS, WEDNESDAY. NOv. 24.  1819     ''    latin   \n",
       "9  PARLIAMENTARY INTELLIGENCE. H OUSE OF L,ORDS, ...  1820     ''  country   \n",
       "\n",
       "             pages                                           filename  \\\n",
       "0  [001, 002, 003]  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...   \n",
       "1  [001, 002, 003]  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...   \n",
       "2  [001, 002, 003]  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...   \n",
       "3       [002, 003]  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...   \n",
       "4       [002, 003]  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...   \n",
       "5  [002, 003, 004]  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...   \n",
       "6  [001, 002, 003]  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...   \n",
       "7  [001, 002, 003]  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...   \n",
       "8  [001, 002, 003]  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...   \n",
       "9  [001, 002, 003]  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/17...   \n",
       "\n",
       "                article_id         issue_id  \n",
       "0  0FFO-1819-DEC01-001-004  0FFO-1819-DEC01  \n",
       "1  0FFO-1819-DEC01-001-004  0FFO-1819-DEC01  \n",
       "2  0FFO-1819-DEC03-001-002  0FFO-1819-DEC03  \n",
       "3  0FFO-1819-DEC18-002-001  0FFO-1819-DEC18  \n",
       "4  0FFO-1819-DEC18-002-001  0FFO-1819-DEC18  \n",
       "5  0FFO-1819-NOV24-002-001  0FFO-1819-NOV24  \n",
       "6  0FFO-1819-NOV25-001-004  0FFO-1819-NOV25  \n",
       "7  0FFO-1819-NOV25-001-004  0FFO-1819-NOV25  \n",
       "8  0FFO-1819-NOV25-001-004  0FFO-1819-NOV25  \n",
       "9  0FFO-1820-OCT06-001-002  0FFO-1820-OCT06  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = {'title':titles, 'year':years, 'author':authors, \n",
    "             'term':terms, 'pages':page_ids, 'filename':filenames, 'article_id':article_ids, 'issue_id':issue_ids}\n",
    "inventory = pd.DataFrame.from_dict(metadata)\n",
    "inventory.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"''\", '(From a Correspondent.)', 'FROM OUR OWN REPORTER.',\n",
       "       \"St. Paul's Cathedral\", '(FROM OUR SPECIAL CORRESPONDENT.)',\n",
       "       'MORIHIRO MATSUDA,',\n",
       "       'Henri Schoup Vlaamse Elsevier Bernard D. Nossiter Washington Post'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory.author.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't many author names included in the metadata for the articles in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1726\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(min(inventory.year))\n",
    "print(max(inventory.year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Export the inventory as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory.to_csv(\"TheTimesArticles_1726-2000_Inventory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Create one TXT file per article \n",
    "Each file contains the text from the field `original_text` and uses its corresponding `article_id` as the filename.\n",
    "\n",
    "**Step 1:** Create a subset of the data that only contains articles written in 1950 or later, including the articles' `original_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>author</th>\n",
       "      <th>term</th>\n",
       "      <th>pages</th>\n",
       "      <th>filename</th>\n",
       "      <th>article_id</th>\n",
       "      <th>issue_id</th>\n",
       "      <th>original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>''</td>\n",
       "      <td>1997</td>\n",
       "      <td>''</td>\n",
       "      <td>musical</td>\n",
       "      <td>[0127]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-2009-1202-0127-007</td>\n",
       "      <td>0FFO-2009-1202</td>\n",
       "      <td>original text: /ZJF/? m I $ THE MUSICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>''</td>\n",
       "      <td>1997</td>\n",
       "      <td>''</td>\n",
       "      <td>musical</td>\n",
       "      <td>[0136]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-2009-1211-0136-005</td>\n",
       "      <td>0FFO-2009-1211</td>\n",
       "      <td>u25A0. ..  Benedict Nightingale enjoys a music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>''</td>\n",
       "      <td>1997</td>\n",
       "      <td>''</td>\n",
       "      <td>pop</td>\n",
       "      <td>[]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-2009-1218-0109-003</td>\n",
       "      <td>0FFO-2009-1218</td>\n",
       "      <td>original text: live web chat Join TZrnes pop c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>''</td>\n",
       "      <td>1997</td>\n",
       "      <td>''</td>\n",
       "      <td>musical</td>\n",
       "      <td>[]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-2009-1219-0298-006</td>\n",
       "      <td>0FFO-2009-1219</td>\n",
       "      <td>THE MUSICAL HIT iaFTHEYEAB: THE STIIY IF FUiKI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>Heirs bells</td>\n",
       "      <td>1997</td>\n",
       "      <td>''</td>\n",
       "      <td>rock</td>\n",
       "      <td>[0071]</td>\n",
       "      <td>/lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-2009-1222-0071-001</td>\n",
       "      <td>0FFO-2009-1222</td>\n",
       "      <td>original text: Heirs bells 20dB Rustling leave...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title  year author     term   pages  \\\n",
       "2271           ''  1997     ''  musical  [0127]   \n",
       "2272           ''  1997     ''  musical  [0136]   \n",
       "2273           ''  1997     ''      pop      []   \n",
       "2274           ''  1997     ''  musical      []   \n",
       "2275  Heirs bells  1997     ''     rock  [0071]   \n",
       "\n",
       "                                               filename  \\\n",
       "2271  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/19...   \n",
       "2272  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/19...   \n",
       "2273  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/19...   \n",
       "2274  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/19...   \n",
       "2275  /lustre/home/sc048/rosaf4/TDA_GDA_1785-2009/19...   \n",
       "\n",
       "                   article_id        issue_id  \\\n",
       "2271  0FFO-2009-1202-0127-007  0FFO-2009-1202   \n",
       "2272  0FFO-2009-1211-0136-005  0FFO-2009-1211   \n",
       "2273  0FFO-2009-1218-0109-003  0FFO-2009-1218   \n",
       "2274  0FFO-2009-1219-0298-006  0FFO-2009-1219   \n",
       "2275  0FFO-2009-1222-0071-001  0FFO-2009-1222   \n",
       "\n",
       "                                          original_text  \n",
       "2271             original text: /ZJF/? m I $ THE MUSICA  \n",
       "2272  u25A0. ..  Benedict Nightingale enjoys a music...  \n",
       "2273  original text: live web chat Join TZrnes pop c...  \n",
       "2274  THE MUSICAL HIT iaFTHEYEAB: THE STIIY IF FUiKI...  \n",
       "2275  original text: Heirs bells 20dB Rustling leave...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory['original_text'] = original_texts\n",
    "subset = inventory[inventory.year >= 1950]\n",
    "subset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1953 1964 1958 1999 1991 1961 1974 1971 1966 1965 1968 1969 1970 1973\n",
      " 1976 1977 1978 1980 1981 1982 1985 1983 1986 1987 1988 1989 1990 1993\n",
      " 1994 1995 1996 1997 1992 1998 2000]\n"
     ]
    }
   ],
   "source": [
    "subset_years = subset.year.unique()\n",
    "subset_years.sort\n",
    "print(subset_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  So the years articles were published in our subset are from 1953 through 2000.\n",
    "\n",
    "**Step 2:** Associate each article's text and ID to one another by creating a dictionary from the `original_text` and `article_id` columns of our subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: live web chat Join TZrnes pop critic Pete Paphides at midday on Monday to dissect the\n"
     ]
    }
   ],
   "source": [
    "id_text = dict(zip(list(subset.article_id),list(subset.original_text)))\n",
    "print(id_text[\"0FFO-2009-1218-0109-003\"][:100]) # First one hundred characters of article with ID 0FFO-2009-1202-0127-007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Write each article's text to a file named as the article's ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTxtFiles(article_dict):\n",
    "    for key,value in article_dict.items():\n",
    "        filepath = \"../TheTimes_DaveO/TheTimesTextFiles_1953-2000/\"+key\n",
    "        file = open(filepath, \"a\")  # a for append\n",
    "        file.write(value)\n",
    "        file.close()\n",
    "    print(\"Text files for each article can now be found in the folder named TheTimesTextFiles_1953-2000!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text files for each article can now be found in the folder named TheTimesTextFiles_1953-2000!\n"
     ]
    }
   ],
   "source": [
    "writeTxtFiles(id_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
