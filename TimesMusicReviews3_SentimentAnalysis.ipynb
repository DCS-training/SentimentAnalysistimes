{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of *The Times* Music Reviews\n",
    "## Part II: Sentiment Analysis\n",
    "*How have artforms been reported?  Is there a status hierarchy between them?  How has this changed over time?*\n",
    "\n",
    "* **Project:** What counts as culture?  Reporting and criticism in The Times 1785-2000\n",
    "* **Project Lead:** Dave O'Brien\n",
    "* **Developer:** Lucy Havens\n",
    "* **Funding:** from the Centre for Data, Culture & Society, University of Edinburgh\n",
    "* **Dataset:** 83,625 reviews about music published in The Times from 1950 through 2009\n",
    "\n",
    "Begun February 2021\n",
    "\n",
    "***\n",
    "\n",
    "First, import required programming libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data loading\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For text analysis\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.text import Text\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('tagsets')  # part of speech tags\n",
    "from nltk.tag import pos_tag\n",
    "# from nltk.classify import NaiveBayesClassifier\n",
    "# from nltk.corpus import subjectivity\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# from nltk.sentiment.util import *\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [UNFINISHED] Sentiment Analysis with NLTK's Naive Bayes Classifier\n",
    "*Code based on: https://www.nltk.org/howto/sentiment.html*\n",
    "\n",
    "Read the data and **tokenize** words (segmenting the running text into lists of words, numbers and punctuation)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"../TheTimes_DaveO/TheTimesTextFiles_1964-2000/\"\n",
    "articles = PlaintextCorpusReader(data_path, \".+\", encoding='utf-8')\n",
    "tokens = articles.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CORONATION',\n",
       " 'HONOURS',\n",
       " 'THE',\n",
       " 'THREE',\n",
       " 'NEW',\n",
       " 'PEERS',\n",
       " ':',\n",
       " 'ONE',\n",
       " 'ORDER',\n",
       " 'OF',\n",
       " 'MERIT',\n",
       " 'THE',\n",
       " 'CORONATION',\n",
       " 'HONOURS',\n",
       " '-',\n",
       " 'continued',\n",
       " 'from',\n",
       " 'pare',\n",
       " '10',\n",
       " 'The']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "...and sentences (segmenting the running text into lists of sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for fileid in articles.fileids():\n",
    "    sentences += [sent_tokenize(articles.raw(fileid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints/0FFO-1953-JUN01-009-001-checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CORONATION HONOURS THE THREE NEW PEERS: ONE ORDER OF MERIT THE CORONATION HONOURS- continued from pare 10 The Honours to be conferred by the Queen to mark her Coronation are announced to-day.',\n",
       " 'They include one new viscount, three barons, six Privy Councillors, five baronets, and many knights.',\n",
       " \"PRIME MINISTER'S LIST VISCOUNT WOOLTON, FREDERICK JAMES, BARON.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(articles.fileids()[0])\n",
    "sentences[0][:3] # print the first three sentences from the first article in the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "That looks good!  Hopefully most of our data has been segmented into sentences this neatly.  Sometimes mistakes in the digitization process can make it difficult for the computer to correctly determine where sentences start and end.  We'll find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Only', 'one', 'mark', 'in', 'any', 'one', 'security', 'is', 'recorded', 'at', 'any', 'one', 'price', ';', 'the', 'sequence', 'of', 'marking', 'is', 'not', 'necessarily', 'that', 'in', 'which', 'the', 'bargains', 'were', 'done', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_articles = []\n",
    "for article in sentences:\n",
    "    tokenized_sentences = []\n",
    "    for s in article:\n",
    "        tokens = word_tokenize(s)\n",
    "        tokenized_sentences += [tokens]\n",
    "    tokenized_articles += [tokenized_sentences]\n",
    "print(tokenized_articles[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Next, let's select a random subsets of the articles for a training set and a test set. We'll put 80% of the data in the training set and the remaining 20% in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles: 571\n",
      "Training articles: 457\n",
      "Test articles: 114\n"
     ]
    }
   ],
   "source": [
    "total_articles = len(tokenized_articles)\n",
    "print(\"Total articles:\",total_articles)\n",
    "training_size = round(total_articles * 0.8)\n",
    "test_size = total_articles - training_size\n",
    "print(\"Training articles:\",training_size)\n",
    "print(\"Test articles:\", test_size)\n",
    "# random.sample(range(0, 1000), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data length: 114 articles\n"
     ]
    }
   ],
   "source": [
    "test_indeces = random.sample(range(0,total_articles),test_size)\n",
    "test_data = []\n",
    "for i in test_indeces:\n",
    "    article = tokenized_articles[i]\n",
    "    test_data += [article]\n",
    "\n",
    "print(\"Test data length:\", len(test_data), \"articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 457 articles\n"
     ]
    }
   ],
   "source": [
    "indeces = range(0,total_articles)\n",
    "training_indeces = []\n",
    "for i in indeces:\n",
    "    if i not in test_indeces:\n",
    "        training_indeces += [i]\n",
    "\n",
    "training_data = []\n",
    "for i in training_indeces:\n",
    "    article = tokenized_articles[i]\n",
    "    training_data += [article]\n",
    "\n",
    "print(\"Training data length:\", len(training_data), \"articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sentiment Analysis with NLTK's VADER\n",
    "**VADER** stands for Valence Aware Dictionary for Sentiment Reasoning. This sentiment analyzer can estimate positivity, neutrality, and negativity, which is called **polarity**, and it can estimate the intensity of these sentiments. VADER estimates the sentiment of a text by computing how much positivity, neutrality, and negativity there is in the text, and then normalizes those computed scores to get a compound score.\n",
    "***\n",
    "References:\n",
    "* https://www.nltk.org/howto/sentiment.html\n",
    "* https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664\n",
    "* https://medium.com/@sharonwoo/sentiment-analysis-with-nltk-422e0f794b8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the `SentimentIntensityAnalyzer`, which I refer to as `analyzer` in my code for brevity, on a sentence from one of the articles in our corpus, just to test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../TheTimes_DaveO/TheTimesMusicReviews_1950-2009\"\n",
    "articles = PlaintextCorpusReader(data_path, \".+/.+\", encoding='utf-8')\n",
    "tokens = articles.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TheTimesMusicReviews_1950-2009_part1/20787'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.fileids()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\", 'SOME', 'NEW', 'SCORES', 'MOTET', 'AND', 'OPERA', 'BY', 'OUR', 'MUSIC']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10] # print the first 10 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *tokens* shown above consist of words, digits, and punctuation.  *Tokenization* is the process of splitting running text into groups of digits (numbers), groups of letters (words), and punctuation marks.  Tokens may also include a grouping that consists of any combination of numbers, punctuation marks, and digits, so if a digitization error occurred in a word, such as `alliance` being digitized as `a1liance` or `a!liance`, the tokenization process would not separate the `1` or `!` out from the other letters.\n",
    "\n",
    "We can also use tokenization to split running text into what the computer estimates are sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for fileid in articles.fileids():\n",
    "    sentences += [sent_tokenize(articles.raw(fileid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'SOME NEW SCORES MOTET AND OPERA BY OUR MUSIC CRIrIC Music publishing has got into its stride once more after the restraints of -war-time conditions, or so it''appears from the scores that arrive for our inspection and review.\",\n",
       " 'The steady stream bears on its broad bosom Church music, chamber music.',\n",
       " 'symphonic music and operas, some of it old in new dress, some of it new.',\n",
       " 'A hand thrust into it on the principle of the lucky dip brings up the largest objects.',\n",
       " \"Though this is not criticism''s most subtle method of discrimination, it has the same sort of excitement as angling-one might catch a masterpiece.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][:5] # print the first 5 sentences of the first article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the sentiment analyzer on these sentences.  The sentiment analyzer [assigns four scores](https://github.com/cjhutto/vaderSentiment#about-the-scoring):\n",
    "* **neg**: a score between 0 and 1 with a higher value indicating a greater proportion of the text has negativity\n",
    "* **neu**: a score between 0 and 1 with a higher value indicating a greater proportion of the text has neutrality\n",
    "* **pos**: a score between 0 and 1 with a higher value indicating a greater proportion of the text has positivity\n",
    "* **compound**: a score between -1 and 1 with negative numbers indicating an overall negative sentiment and positivie numbers, positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SOME NEW SCORES MOTET AND OPERA BY OUR MUSIC CRIrIC Music publishing has got into its stride once more after the restraints of -war-time conditions, or so it''appears from the scores that arrive for our inspection and review.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "The steady stream bears on its broad bosom Church music, chamber music.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "symphonic music and operas, some of it old in new dress, some of it new.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "A hand thrust into it on the principle of the lucky dip brings up the largest objects.\n",
      "{'neg': 0.0, 'neu': 0.7, 'pos': 0.3, 'compound': 0.7184}\n",
      "\n",
      "Though this is not criticism''s most subtle method of discrimination, it has the same sort of excitement as angling-one might catch a masterpiece.\n",
      "{'neg': 0.0, 'neu': 0.741, 'pos': 0.259, 'compound': 0.791}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article = sentences[0][:5]\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    print(analyzer.polarity_scores(sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We'll probably want to decide on a threshold for these scores to decide how large a compound score needs to be for us to consider it positive or negative.  The smallest (and most negative) score the `analyzer` can assign is -1.  The largest (and most positive) score the `analyzer` can assign is 1.  VADER's [documentation](https://github.com/cjhutto/vaderSentiment#about-the-scoring) suggests the following thresholds:\n",
    "* positive: compound score >= 0.5\n",
    "* neutral: -0.5 > compound score < 0.5\n",
    "* negative: compound score <= -0.5\n",
    "\n",
    "For now, though, we'll keep track of all four scores the `analyzer` assigns.  Next, let's run the `analyzer` on all the articles in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>author</th>\n",
       "      <th>term</th>\n",
       "      <th>section</th>\n",
       "      <th>pages</th>\n",
       "      <th>filename</th>\n",
       "      <th>article_id</th>\n",
       "      <th>issue_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20787</th>\n",
       "      <td>SOME NEW SCORES MOTET AND OPERA</td>\n",
       "      <td>1950</td>\n",
       "      <td>BY OUR MUSIC CRITIC</td>\n",
       "      <td>[' bands', ' composer', ' musical', ' opera', ...</td>\n",
       "      <td>Reviews</td>\n",
       "      <td>[]</td>\n",
       "      <td>/lustre/home/dc125/shared/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-1950-JUN30-008-023</td>\n",
       "      <td>0FFO-1950-JUN30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20788</th>\n",
       "      <td>THE ROYAL OPERA \" TRISTAN AND ISOLDE \"</td>\n",
       "      <td>1950</td>\n",
       "      <td>''</td>\n",
       "      <td>[' opera', ' orchestra']</td>\n",
       "      <td>Reviews</td>\n",
       "      <td>[]</td>\n",
       "      <td>/lustre/home/dc125/shared/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-1950-JUN30-008-027</td>\n",
       "      <td>0FFO-1950-JUN30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20789</th>\n",
       "      <td>GROWING TASTE FOR MUSIC PLEA FOR ENLARGED QUEE...</td>\n",
       "      <td>1950</td>\n",
       "      <td>''</td>\n",
       "      <td>[' country']</td>\n",
       "      <td>Reviews</td>\n",
       "      <td>[]</td>\n",
       "      <td>/lustre/home/dc125/shared/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-1950-JUN30-008-032</td>\n",
       "      <td>0FFO-1950-JUN30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20790</th>\n",
       "      <td>ROYAL PHILHARMONIC CONCERT BEECHAM AND MOZART</td>\n",
       "      <td>1950</td>\n",
       "      <td>''</td>\n",
       "      <td>[' orchestra', ' orchestras']</td>\n",
       "      <td>Reviews</td>\n",
       "      <td>['010']</td>\n",
       "      <td>/lustre/home/dc125/shared/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-1950-MAR02-010-006</td>\n",
       "      <td>0FFO-1950-MAR02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20791</th>\n",
       "      <td>MUSICAL JOURNALS SOME NEWCOMERS</td>\n",
       "      <td>1950</td>\n",
       "      <td>BY OUR MUSIC CRITIC</td>\n",
       "      <td>[' musical', ' orchestra', ' orchestras']</td>\n",
       "      <td>Reviews</td>\n",
       "      <td>['007']</td>\n",
       "      <td>/lustre/home/dc125/shared/TDA_GDA_1785-2009/19...</td>\n",
       "      <td>0FFO-1950-MAR03-007-010</td>\n",
       "      <td>0FFO-1950-MAR03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  year  \\\n",
       "20787                    SOME NEW SCORES MOTET AND OPERA  1950   \n",
       "20788             THE ROYAL OPERA \" TRISTAN AND ISOLDE \"  1950   \n",
       "20789  GROWING TASTE FOR MUSIC PLEA FOR ENLARGED QUEE...  1950   \n",
       "20790      ROYAL PHILHARMONIC CONCERT BEECHAM AND MOZART  1950   \n",
       "20791                    MUSICAL JOURNALS SOME NEWCOMERS  1950   \n",
       "\n",
       "                    author                                               term  \\\n",
       "20787  BY OUR MUSIC CRITIC  [' bands', ' composer', ' musical', ' opera', ...   \n",
       "20788                   ''                           [' opera', ' orchestra']   \n",
       "20789                   ''                                       [' country']   \n",
       "20790                   ''                      [' orchestra', ' orchestras']   \n",
       "20791  BY OUR MUSIC CRITIC          [' musical', ' orchestra', ' orchestras']   \n",
       "\n",
       "       section    pages                                           filename  \\\n",
       "20787  Reviews       []  /lustre/home/dc125/shared/TDA_GDA_1785-2009/19...   \n",
       "20788  Reviews       []  /lustre/home/dc125/shared/TDA_GDA_1785-2009/19...   \n",
       "20789  Reviews       []  /lustre/home/dc125/shared/TDA_GDA_1785-2009/19...   \n",
       "20790  Reviews  ['010']  /lustre/home/dc125/shared/TDA_GDA_1785-2009/19...   \n",
       "20791  Reviews  ['007']  /lustre/home/dc125/shared/TDA_GDA_1785-2009/19...   \n",
       "\n",
       "                    article_id         issue_id  \n",
       "20787  0FFO-1950-JUN30-008-023  0FFO-1950-JUN30  \n",
       "20788  0FFO-1950-JUN30-008-027  0FFO-1950-JUN30  \n",
       "20789  0FFO-1950-JUN30-008-032  0FFO-1950-JUN30  \n",
       "20790  0FFO-1950-MAR02-010-006  0FFO-1950-MAR02  \n",
       "20791  0FFO-1950-MAR03-007-010  0FFO-1950-MAR03  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all the file names, which are stored in the 'article_id' column of our inventory\n",
    "inventory = pd.read_csv(\"../TheTimes_DaveO/TheTimesArticles_1950-2009_Inventory.csv\", index_col=0)\n",
    "inventory.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheTimesMusicReviews_1950-2009_part1/20787</td>\n",
       "      <td>0.9897</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheTimesMusicReviews_1950-2009_part1/20788</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheTimesMusicReviews_1950-2009_part1/20789</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheTimesMusicReviews_1950-2009_part1/20790</td>\n",
       "      <td>0.9886</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheTimesMusicReviews_1950-2009_part1/20791</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   article_id  compound  positive  neutral  \\\n",
       "0  TheTimesMusicReviews_1950-2009_part1/20787    0.9897     0.075    0.912   \n",
       "1  TheTimesMusicReviews_1950-2009_part1/20788    0.9978     0.230    0.744   \n",
       "2  TheTimesMusicReviews_1950-2009_part1/20789    0.9912     0.124    0.866   \n",
       "3  TheTimesMusicReviews_1950-2009_part1/20790    0.9886     0.133    0.822   \n",
       "4  TheTimesMusicReviews_1950-2009_part1/20791    0.8225     0.061    0.893   \n",
       "\n",
       "   negative  \n",
       "0     0.013  \n",
       "1     0.025  \n",
       "2     0.010  \n",
       "3     0.044  \n",
       "4     0.046  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "compound_list = []\n",
    "files = articles.fileids()\n",
    "for f in files:\n",
    "    text = open(\"../TheTimes_DaveO/TheTimesMusicReviews_1950-2009/\"+f)\n",
    "    t = text.read()\n",
    "    scores = analyzer.polarity_scores(t)\n",
    "    compound_list += [scores[\"compound\"]]\n",
    "    positive_list += [scores[\"pos\"]]       # VADER's abbreviation for positive\n",
    "    neutral_list += [scores[\"neu\"]]        # VADER's abbreviation for neutral\n",
    "    negative_list += [scores[\"neg\"]]       # VADER's abbreviation for negative\n",
    "    text.close()\n",
    "\n",
    "# Store the scores in a DataFrame (a type of table) with one row per article and one column per score\n",
    "df = pd.DataFrame({\"article_id\":files, \"compound\":compound_list, \"positive\":positive_list, \"neutral\":neutral_list, \"negative\":negative_list})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative articles: 6875\n",
      "Neutral articles: 174\n",
      "Positive articles: 76576\n"
     ]
    }
   ],
   "source": [
    "negative = df[df[\"compound\"] < 0].count()[0]\n",
    "neutral = df[df[\"compound\"] == 0].count()[0]\n",
    "positive = df[df[\"compound\"] > 0].count()[0]\n",
    "print(\"Negative articles:\", negative)\n",
    "print(\"Neutral articles:\", neutral)\n",
    "print(\"Positive articles:\", positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the results to a CSV file so we can easily reference them in Microsoft Excel or another spreadsheet tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../TheTimes_DaveO/TheTimesArticles_1950-2009_VADERSentiments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sentiment Analysis with TensorFlow's Keras\n",
    "\n",
    "* Introduction: https://keras.io/getting_started/intro_to_keras_for_researchers/\n",
    "* LM: https://lena-voita.github.io/nlp_course.html \n",
    "* Seq2seq and Attention: https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sentiment Analysis with TextBlob's Pattern Analyzer\n",
    "https://textblob.readthedocs.io/en/dev/advanced_usage.html#advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
